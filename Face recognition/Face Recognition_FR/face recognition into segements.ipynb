{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b3057",
   "metadata": {},
   "source": [
    "### Face Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the directory containing the face images\n",
    "faces_dir = \"face dataset/\"\n",
    "\n",
    "# Initialize lists to store the face encodings and corresponding names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "count = 0\n",
    "# Loop over each file in the faces directory\n",
    "for filename in os.listdir(faces_dir):\n",
    "    # Extract the name and id from the filename\n",
    "    \n",
    "    name_id = os.path.splitext(filename)[0] #extracting the name_id from file  \n",
    "\n",
    "    # Load the face image\n",
    "    img = face_recognition.load_image_file(os.path.join(faces_dir, filename))\n",
    "\n",
    "    # Encode the face and append to the lists\n",
    "    encoding = face_recognition.face_encodings(img)[0]\n",
    "    known_face_encodings.append(encoding)\n",
    "    known_face_names.append(name_id)\n",
    "    count+=1\n",
    "print(f'Total faces: {count}')    \n",
    "print(known_face_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6321dd",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b32340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the default camera device (0) for video capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame from camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB (face_recognition library uses RGB)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Find all the faces and their encodings in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f35b6",
   "metadata": {},
   "source": [
    "### Encode Faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ed97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the recognized individual ids and their corresponding prediction scores\n",
    "individual_ids = []\n",
    "prediction_scores = []\n",
    "\n",
    "# Loop over each face encoding in the current frame\n",
    "for face_encoding in face_encodings:\n",
    "    # Try to recognize the face\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.6)\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # Find the index of the first matching face (if any)\n",
    "    if True in matches:\n",
    "        first_match_index = matches.index(True)\n",
    "        name = known_face_names[first_match_index]\n",
    "    \n",
    "    # Add the individual id and prediction score to the lists\n",
    "    individual_id = str(name_id.split(\"_\")[1])\n",
    "    individual_ids.append(individual_id)\n",
    "    prediction_score = face_recognition.face_distance([known_face_encodings[first_match_index]], face_encoding)[0]\n",
    "    prediction_scores.append(prediction_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aaa14f",
   "metadata": {},
   "source": [
    "### Recognize Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59699ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognized individuals dictionary\n",
    "recognized_individuals = {}\n",
    "\n",
    "# Loop over each individual id in the list of recognized ids\n",
    "for individual_id in individual_ids:\n",
    "    # If the id has not been recognized before, add to the dictionary with a count of 1\n",
    "    if individual_id not in recognized_individuals:\n",
    "        recognized_individuals[individual_id] = 1\n",
    "    # If the id has been recognized before, increment the count\n",
    "    else:\n",
    "        recognized_individuals[individual_id] += 1\n",
    "\n",
    "# Loop over each recognized individual in the dictionary\n",
    "for individual_id, count in recognized_individuals.items():\n",
    "    # If the individual has been recognized more than once, mark attendance\n",
    "    if count > 1:\n",
    "        name = \"Name \" + str(individual_id)\n",
    "        # Get the current date and time\n",
    "        date = datetime.datetime.now().strftime(\"%d-%m-%Y\")\n",
    "        time = datetime.datetime.now().strftime(\"%H:%M\")\n",
    "        # Write the attendance record to the CSV file\n",
    "        with open(\"attendance.csv\", \"a+\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([individual_id, name, date, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecfad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd30d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd345e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Load images from the given folder and return a list of face encodings and IDs\n",
    "def load_images_from_folder(folder):\n",
    "    encodings = []\n",
    "    ids = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = face_recognition.load_image_file(os.path.join(folder, filename))\n",
    "        encoding = face_recognition.face_encodings(img)[0]\n",
    "        id = os.path.splitext(filename)[0]\n",
    "        id = str(id)  # convert ID to string\n",
    "        encodings.append(encoding)\n",
    "        ids.append(id)\n",
    "    return encodings, ids\n",
    "\n",
    "# Train the face recognition model with the given encodings and IDs\n",
    "def train(encodings, ids):\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.train(encodings, np.array(ids))\n",
    "    return recognizer\n",
    "\n",
    "# Recognize faces in the given frame using the given face recognition model\n",
    "def recognize(frame, face_locations, face_encodings, recognizer, id_to_name):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    individual_names = []\n",
    "    for encoding in face_encodings:\n",
    "        individual_id, predict, _ = recognizer.predict(encoding)\n",
    "        individual_id = str(individual_id)  # convert ID to string\n",
    "        individual_name = id_to_name.get(individual_id, 'Unknown')\n",
    "        individual_names.append(individual_name)\n",
    "    for (top, right, bottom, left), name in zip(face_locations, individual_names):\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with the name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    return frame, individual_names\n",
    "\n",
    "# Main function for recognizing faces in the live video from the webcam\n",
    "def recognize_faces():\n",
    "    # Load the face encodings and IDs from the \"face dataset\" directory\n",
    "    encodings, ids = load_images_from_folder('face dataset')\n",
    "\n",
    "    # Train the face recognition model with the encodings and IDs\n",
    "    recognizer = train(encodings, ids)\n",
    "\n",
    "    # Load the dictionary mapping IDs to names\n",
    "    id_to_name = {\n",
    "        'qd123': 'John Doe',\n",
    "        'ab456': 'Jane Smith',\n",
    "        # add more mappings as needed\n",
    "    }\n",
    "\n",
    "    # Initialize variables for attendance tracking\n",
    "    col_names = ['Id', 'Name', 'Date', 'Time']\n",
    "    attendance = pd.DataFrame(columns=col_names)\n",
    "\n",
    "    # Open the default camera device (0) for video capture\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7101716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277cafdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce552c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a785dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426394ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d433588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harsh_QD138\n",
      "y_QD0568\n",
      "Unknown\n",
      "Harsh_QD138\n",
      "H_QD0354\n",
      "H_QD0354\n",
      "H_QD0354\n",
      "Harsh_QD138\n",
      "y_QD0568\n",
      "y_QD0568\n",
      "y_QD0568\n",
      "\n",
      " [INFO] Exiting Program \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Path to the face dataset directory\n",
    "faces_dir = 'face dataset/'\n",
    "\n",
    "# Initialize arrays for the face encodings and corresponding names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Loop over each file in the faces directory\n",
    "for filename in os.listdir(faces_dir):\n",
    "    # Load the image file\n",
    "    image = face_recognition.load_image_file(os.path.join(faces_dir, filename))\n",
    "\n",
    "    name_id = os.path.splitext(filename)[0] #extracting the name_id from file\n",
    "\n",
    "    # Encode the face and append the encoding and name to the arrays\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    known_face_encodings.append(face_encoding)\n",
    "    known_face_names.append(name_id)\n",
    "\n",
    "# # Save the face encodings and names to a pickle file\n",
    "# encodings_data = {'encodings': known_face_encodings, 'names': known_face_names}\n",
    "# with open('encodings.pickle', 'wb') as f:\n",
    "#     f.write(pickle.dumps(encodings_data))\n",
    "\n",
    "# # Load the encodings from the pickle file\n",
    "# with open('encodings.pickle', 'rb') as f:\n",
    "#     encodings_data = pickle.load(f)\n",
    "#     known_face_encodings = encodings_data['encodings']\n",
    "#     known_face_names = encodings_data['names']\n",
    "\n",
    "# Initialize the attendance dataframe\n",
    "col_names = ['Name_ID', 'Date', 'Time']\n",
    "attendance = pd.DataFrame(columns=col_names)\n",
    "\n",
    "# Initialize the font for labeling the recognized faces\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Open the default camera device (0) for video capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame from camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for face recognition\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    #rgb_frame = cv2.resize(image,(0,0),None,0.25,0.25)\n",
    "    #rgb_frame = cv2.cvtColor(rgb_frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Loop over each face in the frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # Recognize the user ID for the face using the known encodings\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Find the best match for the face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            print(name)\n",
    "\n",
    "            # Mark attendance for the recognized user\n",
    "            ts = time.time()\n",
    "            date = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y')\n",
    "            timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "            attendance.loc[len(attendance)] = [name_id, date, timeStamp]\n",
    "            # Remove duplicates based on Id and Date columns\n",
    "            attendance = attendance.drop_duplicates(subset=['Name_ID','Date'],keep='first')\n",
    "            # Save attendance record to CSV file\n",
    "            attendance.to_csv('Attendance.csv',index=False,header=True)\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "            print(name)\n",
    "\n",
    "        # Draw a box and label around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 240, 0), 2)\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.75, (0, 240, 0), 2)\n",
    "\n",
    "#     ## Record attendance\n",
    "#         if name != \"Unknown\":\n",
    "#             now = datetime.datetime.now()\n",
    "#             date = now.strftime(\"%Y-%m-%d\")\n",
    "#             time = now.strftime(\"%H:%M:%S\")\n",
    "            \n",
    "#             # Add the attendance to the dictionary\n",
    "#             if name not in attendance:\n",
    "#                 attendance[name] = []\n",
    "#             attendance[name].append((date, time))\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Quit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Wait for a key press to exit the program\n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27: # Press 'ESC' for exiting video\n",
    "        break\n",
    "    elif (k == ord('c')):\n",
    "        # Check if the directory exists and create it if it doesn't\n",
    "        if not os.path.exists(\"CapturedImages\"):\n",
    "            os.mkdir(\"CapturedImages\")\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(f'CapturedImages/{individual_name}_{time.strftime(\"%d%m%Y-%H%M\")}.jpg', frame)\n",
    "        #cv2.imwrite(r'C:\\Users\\Q209\\Current projects\\Face Recognition_jupyter/User_\" + individual_name + \".jpg\"',frame)\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program \")\n",
    "# # Save the attendance to a CSV file\n",
    "# with open('attendance.csv', 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(col_names)\n",
    "    \n",
    "#     for name, attendance_list in attendance.items():\n",
    "#         for date, time in attendance_list:\n",
    "#             writer.writerow([name, date, time])\n",
    "\n",
    "# Release handle to the webcam\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ddbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d9690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# Load face encodings and names\n",
    "encodings_file = \"encodings.pickle\"\n",
    "data = pickle.loads(open(encodings_file, \"rb\").read())\n",
    "known_face_encodings = data[\"encodings\"]\n",
    "known_face_names = data[\"names\"]\n",
    "\n",
    "# Initialize some variables\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "attendance = {}\n",
    "col_names = ['Name', 'Date', 'Time']\n",
    "\n",
    "# Open the default camera device (0) for video capture\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "    \n",
    "    # Find all the faces and face encodings in the current frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "    # Loop through each face in this frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if this face is a match for any known faces\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "        \n",
    "        # If we have a match, get the name from the known_face_names array\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_face_names[first_match_index]\n",
    "            \n",
    "        # Draw a box around the face and label it with the name\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Record attendance\n",
    "        if name != \"Unknown\":\n",
    "            now = datetime.datetime.now()\n",
    "            date = now.strftime(\"%d-%m-%Y\")\n",
    "            time = now.strftime(\"%H:%M\")\n",
    "            \n",
    "            # Add the attendance to the dictionary\n",
    "            if name not in attendance:\n",
    "                attendance[name] = []\n",
    "            attendance[name].append((date, time))\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Quit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Save the attendance to a CSV file\n",
    "with open('attendance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(col_names)\n",
    "    \n",
    "    for name, attendance_list in attendance.items():\n",
    "        for date, time in attendance_list:\n",
    "            writer.writerow([name, date, time])\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ae071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
