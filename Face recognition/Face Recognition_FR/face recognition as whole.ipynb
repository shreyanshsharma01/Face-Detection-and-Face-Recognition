{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9906005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4335aa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (443888093.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def train\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "# Load face dataset\n",
    "face_dataset_path = \"face dataset/\"\n",
    "face_dataset = []\n",
    "id_to_name = {}\n",
    "for file_name in os.listdir(face_dataset_path):\n",
    "    name, _ = file_name.split(\"_\")\n",
    "    id_to_name[len(face_dataset)] = name\n",
    "    image_path = os.path.join(face_dataset_path, file_name)\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    face_dataset.append(face_encoding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21901d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load face dataset\n",
    "face_dataset_path = \"face dataset/\"\n",
    "face_dataset = []\n",
    "id_to_name = {}\n",
    "for file_name in os.listdir(face_dataset_path):\n",
    "    name, _ = file_name.split(\"_\")\n",
    "    id_to_name[len(face_dataset)] = name\n",
    "    image_path = os.path.join(face_dataset_path, file_name)\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "    face_dataset.append(face_encoding)\n",
    "\n",
    "# Create attendance dataframe\n",
    "col_names = ['Id', 'Name', 'Date', 'Time']\n",
    "attendance = pd.DataFrame(columns=col_names)\n",
    "\n",
    "# Open the default camera device (0) for video capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame from camera\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Loop over each face in the frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # Recognize the user ID for the face using the face dataset\n",
    "        matches = face_recognition.compare_faces(face_dataset, face_encoding)\n",
    "        individual_id = None\n",
    "        for i, match in enumerate(matches):\n",
    "            if match:\n",
    "                individual_id = i\n",
    "                break\n",
    "\n",
    "        # Get the user name for the recognized user ID from the dictionary\n",
    "        if individual_id is not None:\n",
    "            individual_name = id_to_name[individual_id]\n",
    "            confidence = 100\n",
    "        else:\n",
    "            individual_name = \"Unknown\"\n",
    "            confidence = 0\n",
    "\n",
    "        # Mark attendance for the recognized user\n",
    "        ts = time.time()\n",
    "        date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "        timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "        attendance.loc[len(attendance)] = [individual_id, individual_name, date, timeStamp]\n",
    "\n",
    "        # Display the name label and bounding box around the face\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.75\n",
    "        thickness = 2\n",
    "        label = f\"{individual_name} ({confidence:.0f}%)\"\n",
    "        color = (0, 255, 0) if individual_id is not None else (0, 0, 255)\n",
    "        cv2.putText(frame, label, (left, top - 10), font, font_scale, color, thickness)\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, thickness)\n",
    "\n",
    "        # Save attendance record to CSV file\n",
    "        attendance.to_csv('Attendance.csv', index=False)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b55910a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Q209\\\\Current projects\\\\Face Recognition_FR'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e886c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
