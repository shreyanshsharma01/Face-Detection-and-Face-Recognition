{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b945e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87566974",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_detector = cv2.CascadeClassifier(r'C:\\Users\\Q209\\Current projects\\Face Recognition\\haarcascade_frontalface_default.xml')\n",
    "face_recognizer.read(r'C:\\Users\\Q209\\Current projects\\Face Recognition\\Trainer_model/faces_trained.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358972fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3b27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Exiting Program \n"
     ]
    }
   ],
   "source": [
    "# Define the path to the face dataset directory\n",
    "dataset_directory = \"face_dataset\"\n",
    "# Get the list of user directories within the face dataset directory\n",
    "individual_directories = os.listdir(dataset_directory)\n",
    "\n",
    "# Create a dictionary to map user IDs to user names\n",
    "id_to_name = {}\n",
    "\n",
    "# Loop over each user directory and add the user ID and name to the dictionary\n",
    "for individual_directory in individual_directories:\n",
    "    # Path to the current individual directory\n",
    "    current_directory = os.path.join(dataset_directory, individual_directory)\n",
    "    # List of image files within the current individual directory\n",
    "    image_files = os.listdir(current_directory)\n",
    "    '''individual_name = image_files.split(\"_\")[0]\n",
    "    individual_id =  int(image_files.split(\"_\")[1])'''\n",
    "    for image_file in image_files:\n",
    "        # Path to the current image file\n",
    "        image_path = os.path.join(current_directory, image_file) \n",
    "        individual_id = int(os.path.basename(image_path).split(\"_\")[1])\n",
    "         # Get the user name from the directory name\n",
    "        individual_name = individual_directory.split(\"_\")[0]\n",
    "        # Add the user ID and name to the dictionary'''\n",
    "    id_to_name[individual_id] = individual_name\n",
    "\n",
    "\n",
    "# Define the font and text color for the name label\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "color = (0, 255, 0)\n",
    "\n",
    "# Open the default camera device (0) for video capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(100, 100))\n",
    "    # Loop over each face in the frame\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region from the frame\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        # Resize the face region to a fixed size\n",
    "        face = cv2.resize(face, (100, 100))\n",
    "        # Recognize the user ID for the face using the trained recognizer\n",
    "        individual_id, confidence = face_recognizer.predict(face)\n",
    "        # Get the user name for the recognized user ID from the dictionary\n",
    "        individual_name = id_to_name[individual_id]\n",
    "        \n",
    "        if (confidence > 77):\n",
    "            cv2.putText(frame, individual_name, (x, y-10), font, 0.75, (255,255,255), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,255), 2)\n",
    "        else:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 77, 0), 2)\n",
    "            cv2.putText(frame, 'Unknown face', (x, y-10), font, 0.75, (255,255,255), 2)\n",
    "        # Draw a rectangle around the face region\n",
    "        #cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        # Add the user name label to the top of the face region\n",
    "        #cv2.putText(frame, individual_name, (x, y-10), font, 0.75, color, 2)\n",
    "    # Show the frame in a window\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    # Wait for a key press to exit the program\n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27: # Press 'ESC' for exiting video\n",
    "        break\n",
    "    elif (k == ord('c')):\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"D:\\Internship ML\\Projects\\Open cv/Face images/User_\" + str(id) + \".jpg\",frame)\n",
    "        break\n",
    "        \n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program \")\n",
    "# Release the camera device and close all windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1332b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa097dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    frame = cv2.flip(frame, 1) # Flip vertically\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(100, 100))\n",
    "    \n",
    "    # Loop over each face in the frame\n",
    "    for(x,y,w,h) in faces:\n",
    "        # Draw a rectangle around the face region\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        count = count+1\n",
    "         # Take 3 face sample and stop video\n",
    "        # Recognize the user ID for the face using the trained recognizer\n",
    "        individual_id, confidence = face_recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        # Get the user name for the recognized user ID from the dictionary\n",
    "        individual_name = id_to_name[individual_id]\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        \n",
    "        if (confidence < 100):\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            individual_id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            \n",
    "        # Add the user name label to the top of the face region\n",
    "        cv2.putText(frame,individual_name, (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        #cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "        cv2.imshow('camera',frame) \n",
    "    \n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27: # Press 'ESC' for exiting video\n",
    "        break\n",
    "    elif (k == ord('c')):\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"D:\\Internship ML\\Projects\\Open cv/Face images/User_\" + str(id) + \".jpg\",frame)\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program \")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad70b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the current individual directory\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image files within the current individual directory\n",
    "image_files = os.listdir(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb33f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e43753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8d7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e2268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_directory = \"face_dataset\"\n",
    "individual_directory = os.listdir(dataset_directory)\n",
    "individual_id = int(individual_directory)\n",
    "individual_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_directory = os.listdir(dataset_directory)\n",
    "individual_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca3a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47975644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5999ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c38490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale( gray, scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH)),\n",
    "       )\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        count = count+1\n",
    "         # Take 3 face sample and stop video\n",
    "\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "        cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27: # Press 'ESC' for exiting video\n",
    "        break\n",
    "    elif (k == ord('c')):\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"D:\\Internship ML\\Projects\\Open cv/Face images/User_\" + str(id) + \".jpg\",img)\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program \")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f94c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f79b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182e454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98e64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11ad3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3236fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the path to the trained recognizer XML file\n",
    "recognizer_file = \"lbph_trained.xml\"\n",
    "\n",
    "# Create a LBPH recognizer object and load the trained recognizer from the file\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(recognizer_file)\n",
    "\n",
    "# Define the path to the Haar cascade file\n",
    "cascade_path = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create a face detector object using the Haar cascade\n",
    "detector = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# Define the path to the face dataset directory\n",
    "dataset_directory = \"face_dataset\"\n",
    "\n",
    "# Get the list of user directories within the face dataset directory\n",
    "individual_directories = os.listdir(dataset_directory)\n",
    "\n",
    "# Create a dictionary to map user IDs to user names\n",
    "id_to_name = {}\n",
    "\n",
    "# Loop over each user directory and add the user ID and name to the dictionary\n",
    "for individual_directory in individual_directories:\n",
    "    # Get the user ID from the directory name\n",
    "    individual_id = int(individual_directory.split(\"_\")[0])\n",
    "    # Get the user name from the directory name\n",
    "    individual_name = individual_directory.split(\"_\")[1]\n",
    "    # Add the user ID and name to the dictionary\n",
    "    id_to_name[individual_id] = individual_name\n",
    "\n",
    "# Define the font and text color for the name label\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "color = (0, 255, 0)\n",
    "\n",
    "# Open the default camera device (0) for video capture\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop over each frame from the camera\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    ret, frame = camera.read()\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(100, 100))\n",
    "    # Loop over each face in the frame\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face region from the frame\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        # Resize the face region to a fixed size\n",
    "        face = cv2.resize(face, (100, 100))\n",
    "        # Recognize the user ID for the face using the trained recognizer\n",
    "        individual_id, confidence = recognizer.predict(face)\n",
    "        # Get the user name for the recognized user ID from the dictionary\n",
    "        individual_name = id_to_name[individual_id]\n",
    "        # Draw a rectangle around the face region\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        # Add the user name label to the top of the face region\n",
    "        cv2.putText(frame, individual_name, (x, y-10), font, 0.75, color, 2)\n",
    "    # Show the frame in a window\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    # Wait for a key press to exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera device and close all windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97bcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
